@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
} 

@inproceedings{d2016estimating,
  title={Estimating maximum expected value through gaussian approximation},
  author={D'Eramo, Carlo and Restelli, Marcello and Nuara, Alessandro},
  booktitle={Proc. ICML},
  pages={1032--1040},
  year={2016}
}

@article{smith2006optimizer,
  title={The optimizer's curse: Skepticism and postdecision surprise in decision analysis},
  author={Smith, James E and Winkler, Robert L},
  journal={Management Science},
  volume={52},
  number={3},
  pages={311--322},
  year={2006},
  publisher={INFORMS}
}

@article{van2004rational,
  title={Rational overoptimism (and other biases)},
  author={Van den Steen, Eric},
  journal={American Economic Review},
  pages={1141--1151},
  year={2004},
  publisher={JSTOR}
}

@inproceedings{van2010double,
  title={Double Q-learning},
  author={Hasselt, Hado van},
  booktitle={Proc. NIPS},
  pages={2613--2621},
  year={2010}
}

@incollection{NIPS2011_4251,
title = {Speedy Q-Learning},
author = {Ghavamzadeh, Mohammad and Hilbert J. Kappen and Mohammad G. Azar and R\'{e}mi Munos},
booktitle = {Proc. NIPS},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2411--2419},
year = {2011},
publisher = {Curran Associates, Inc.}
}

@article{van2013estimating,
  title={Estimating the Maximum Expected Value: an Analysis of (Nested) Cross-Validation and the Maximum Sample Average},
  author={Hasselt, Hado van},
  journal={arXiv preprint arXiv:1302.7175},
  year={2013}
}

@inproceedings{Peters2010RelativeEP,
  title={Relative Entropy Policy Search},
  author={Jan Peters and Katharina Mulling and Yasemin Altun},
  booktitle={Proc. AAAI},
  year={2010}
}

@inproceedings{crites1996improving,
  title={Improving elevator performance using reinforcement learning},
  author={Crites, Robert H and Barto, Andrew G},
  booktitle={Proc. NIPS},
  pages={1017--1023},
  year={1996}
}

@inproceedings{bao2008infinite,
  title={Infinite-Horizon Policy-Gradient Estimation with Variable Discount Factor for Markov Decision Process},
  author={Bao, Bing-Kun and Yin, Bao-Qun and Xi, Hong-Sheng},
  booktitle={Proc. ICICIC},
  pages={584--584},
  year={2008},
  organization={IEEE}
}

@article{franccois2015discount,
  title={How to discount deep reinforcement learning: Towards new dynamic strategies},
  author={Fran{\c{c}}ois-Lavet, Vincent and Fonteneau, Raphael and Ernst, Damien},
  journal={arXiv preprint arXiv:1512.02011},
  year={2015}
}

@Inbook{EvenDar2001,
author={Even-Dar, Eyal and Mansour, Yishay},
editor={Helmbold, David and Williamson, Bob},
title={Learning Rates for Q-Learning},
year={2001},
publisher={Springer Berlin Heidelberg},
pages={589--604}
}

@inproceedings{lee2013bias,
  title={Bias-corrected Q-learning to control max-operator bias in Q-learning},
  author={Lee, Daewoo and Defourny, Boris and Powell, Warren B},
  booktitle={Proc. ADPRL},
  pages={93--99},
  year={2013},
  organization={IEEE}
}

@article{schweighofer2003meta,
  title={Meta-learning in reinforcement learning},
  author={Schweighofer, Nicolas and Doya, Kenji},
  journal={Neural Networks},
  volume={16},
  number={1},
  pages={5--9},
  year={2003},
  publisher={Elsevier}
}

@Inbook{Kobayashi2009,
author={Kobayashi, Kunikazu and Mizoue, Hiroyuki and Kuremoto, Takashi and Obayashi, Masanao},
title={A Meta-learning Method Based on Temporal Difference Error},
year={2009},
publisher={Springer Berlin Heidelberg},
pages={530--537},
}

@article{mohagheghi2007proportional,
  title={A proportional-integrator type adaptive critic design-based neurocontroller for a static compensator in a multimachine power system},
  author={Mohagheghi, Salman and del Valle, Yamille and Venayagamoorthy, Ganesh Kumar and Harley, Ronald G},
  journal={IEEE Transactions on Industrial Electronics},
  volume={54},
  number={1},
  pages={86--96},
  year={2007},
  publisher={IEEE}
}

@Inbook{Tewari2007,
author={Tewari, Ambuj and Bartlett, Peter L.},
title={Bounded Parameter Markov Decision Processes with Average Reward Criterion},
year={2007},
pages={263--277},
}

@inproceedings{yoshida2013reinforcement,
  title={Reinforcement learning with state-dependent discount factor},
  author={Yoshida, Naoto and Uchibe, Eiji and Doya, Kenji},
  booktitle={Proc. ICDL},
  pages={1--6},
  year={2013},
  organization={IEEE}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}

@inproceedings{van2016deep,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Hasselt, Hado van and Guez, Arthur and Silver, David},
  booktitle={Proc. AAAI},
  pages={2094--2100},
  year={2016}
}

